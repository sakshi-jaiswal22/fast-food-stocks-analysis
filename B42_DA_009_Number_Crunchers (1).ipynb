{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " **Mounting Google Drive**"
      ],
      "metadata": {
        "id": "FqFZujLrMjqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaAAMv4S7HA5",
        "outputId": "c2d15ea7-4778-49cd-8e71-3d3682d829e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Locating the Extracted Files**"
      ],
      "metadata": {
        "id": "Buy-MaHIMvnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/archive (13).zip (Unzipped Files)/\"\n",
        "files = os.listdir(folder_path)\n",
        "print(files)  # List all extracted files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRP3KyzGHb4p",
        "outputId": "a1718c4c-0d38-48b1-dd23-56b6f25da28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['YUM.csv', 'LKNCY.csv', 'DPZ.csv', 'WEN.csv', 'QSR.csv', 'MCD.csv', 'DNUT.csv', 'BRK-A.csv', 'PZZA.csv', 'SBUX.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading a File**"
      ],
      "metadata": {
        "id": "LDljP6sMM0rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/archive (13).zip (Unzipped Files)/QSR.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.head())  # Display first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHTpkvShHnXE",
        "outputId": "33a5342a-55f8-45ed-d62d-addf685e181c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date       Open       High        Low      Close  Adj Close   Volume\n",
            "0  2014-12-11  35.049999  36.970001  34.880001  36.709999  28.332481   601900\n",
            "1  2014-12-12  37.220001  37.520000  35.049999  35.410000  27.329147  3836400\n",
            "2  2014-12-15  35.869999  35.950001  34.860001  35.290001  27.236544  1898600\n",
            "3  2014-12-16  35.410000  35.750000  35.349998  35.459999  27.367741  4877500\n",
            "4  2014-12-17  35.470001  36.599998  35.439999  36.169998  27.915712  2500200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading All 10 Datasets**"
      ],
      "metadata": {
        "id": "uq0XwmXFM_HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {}  # Dictionary to store dataframes\n",
        "\n",
        "for file in files:\n",
        "    if file.endswith(\".csv\"):  # Ensure it's a CSV file\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        dfs[file] = pd.read_csv(file_path)\n",
        "\n",
        "# Print first few rows of each dataset\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nDataset: {name}\")\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT-e6tMsI_Ii",
        "outputId": "81119613-c5c8-414c-f95e-4e42f294feca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: YUM.csv\n",
            "         Date      Open      High       Low     Close  Adj Close    Volume\n",
            "0  1997-09-17  5.167146  5.436736  5.167146  5.234543   3.617383  29185406\n",
            "1  1997-09-18  5.301941  5.414270  5.257009  5.414270   3.741585   6731884\n",
            "2  1997-09-19  5.403037  5.571531  5.403037  5.436736   3.757111   3440221\n",
            "3  1997-09-22  5.391804  5.459202  5.380572  5.391804   3.726059   5831072\n",
            "4  1997-09-23  5.391804  5.414270  5.380572  5.391804   3.726059   2738601\n",
            "\n",
            "Dataset: LKNCY.csv\n",
            "         Date   Open       High        Low      Close  Adj Close    Volume\n",
            "0  2019-05-17  25.02  25.959999  18.809999  20.379999  20.379999  38937500\n",
            "1  2019-05-20  21.02  21.020000  18.400000  18.610001  18.610001   8186600\n",
            "2  2019-05-21  18.59  18.740000  17.330000  17.330000  17.330000   8572300\n",
            "3  2019-05-22  17.00  17.330000  14.700000  14.750000  14.750000  19697300\n",
            "4  2019-05-23  14.47  15.950000  13.710000  15.790000  15.790000   9626500\n",
            "\n",
            "Dataset: DPZ.csv\n",
            "         Date   Open   High    Low  Close  Adj Close    Volume\n",
            "0  2004-07-13  14.00  14.10  13.49  13.50   6.144002  14964100\n",
            "1  2004-07-14  13.50  13.55  12.91  13.44   6.116695   2801000\n",
            "2  2004-07-15  13.45  13.85  13.35  13.84   6.298741   1276200\n",
            "3  2004-07-16  13.87  13.90  13.51  13.83   6.294190   1488200\n",
            "4  2004-07-19  13.80  13.80  13.35  13.52   6.153106    966200\n",
            "\n",
            "Dataset: WEN.csv\n",
            "         Date  Open   High    Low  Close  Adj Close  Volume\n",
            "0  1980-05-06   0.0  2.250  2.125  2.125   0.401966     300\n",
            "1  1980-05-07   0.0  2.375  2.250  2.250   0.425611    2000\n",
            "2  1980-05-08   0.0  2.375  2.250  2.375   0.449256    1700\n",
            "3  1980-05-09   0.0  2.375  2.250  2.375   0.449256     700\n",
            "4  1980-05-12   0.0  2.375  2.250  2.250   0.425611    1800\n",
            "\n",
            "Dataset: QSR.csv\n",
            "         Date       Open       High        Low      Close  Adj Close   Volume\n",
            "0  2014-12-11  35.049999  36.970001  34.880001  36.709999  28.332481   601900\n",
            "1  2014-12-12  37.220001  37.520000  35.049999  35.410000  27.329147  3836400\n",
            "2  2014-12-15  35.869999  35.950001  34.860001  35.290001  27.236544  1898600\n",
            "3  2014-12-16  35.410000  35.750000  35.349998  35.459999  27.367741  4877500\n",
            "4  2014-12-17  35.470001  36.599998  35.439999  36.169998  27.915712  2500200\n",
            "\n",
            "Dataset: MCD.csv\n",
            "         Date  Open      High       Low     Close  Adj Close   Volume\n",
            "0  1966-07-05   0.0  0.273663  0.267490  0.269547   0.115991   388800\n",
            "1  1966-07-06   0.0  0.283951  0.267490  0.283951   0.122190   692550\n",
            "2  1966-07-07   0.0  0.291152  0.271605  0.273663   0.117762  1858950\n",
            "3  1966-07-08   0.0  0.276749  0.267490  0.276749   0.119090  1239300\n",
            "4  1966-07-11   0.0  0.283951  0.272634  0.275720   0.118648   656100\n",
            "\n",
            "Dataset: DNUT.csv\n",
            "         Date       Open       High    Low      Close  Adj Close    Volume\n",
            "0  2021-07-01  16.299999  21.690001  15.50  21.000000  20.361467  40888200\n",
            "1  2021-07-02  19.854000  20.450001  18.32  19.120001  18.538637   8631400\n",
            "2  2021-07-06  18.900000  19.120001  17.00  17.000000  16.483095   3973000\n",
            "3  2021-07-07  17.289000  18.160000  17.00  17.780001  17.239378   3213500\n",
            "4  2021-07-08  17.250000  18.350000  17.00  18.200001  17.646606   5448300\n",
            "\n",
            "Dataset: BRK-A.csv\n",
            "         Date   Open   High    Low  Close  Adj Close  Volume\n",
            "0  1980-03-17  290.0  310.0  290.0  290.0      290.0   10000\n",
            "1  1980-03-18  290.0  290.0  290.0  290.0      290.0       0\n",
            "2  1980-03-19  290.0  310.0  290.0  290.0      290.0   20000\n",
            "3  1980-03-20  290.0  290.0  290.0  290.0      290.0       0\n",
            "4  1980-03-21  290.0  290.0  290.0  290.0      290.0       0\n",
            "\n",
            "Dataset: PZZA.csv\n",
            "         Date      Open      High       Low     Close  Adj Close    Volume\n",
            "0  1993-06-08  2.000000  2.055556  1.888889  1.944444   1.635053  16986600\n",
            "1  1993-06-09  2.000000  2.222222  1.944444  2.194444   1.845275   2650500\n",
            "2  1993-06-10  2.250000  2.333333  2.055556  2.111111   1.775201   3562200\n",
            "3  1993-06-11  2.083333  2.277778  2.083333  2.250000   1.891991   1931400\n",
            "4  1993-06-14  2.305556  2.333333  2.222222  2.333333   1.962063    730800\n",
            "\n",
            "Dataset: SBUX.csv\n",
            "         Date      Open      High       Low     Close  Adj Close     Volume\n",
            "0  1992-06-26  0.328125  0.347656  0.320313  0.335938   0.259137  224358400\n",
            "1  1992-06-29  0.339844  0.367188  0.332031  0.359375   0.277216   58732800\n",
            "2  1992-06-30  0.367188  0.371094  0.343750  0.347656   0.268176   34777600\n",
            "3  1992-07-01  0.351563  0.359375  0.339844  0.355469   0.274203   18316800\n",
            "4  1992-07-02  0.359375  0.359375  0.347656  0.355469   0.274203   13996800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking for Missing Values**"
      ],
      "metadata": {
        "id": "1ud8d4VhNiJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    print(f\"\\nChecking missing values for {name}:\")\n",
        "    print(df.isnull().sum())  # Count of missing values per column\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm1t6EXpLXvc",
        "outputId": "316fef03-7060-4fd8-b177-86f3c4320c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking missing values for YUM.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for LKNCY.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for DPZ.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for WEN.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for QSR.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for MCD.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for DNUT.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for BRK-A.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for PZZA.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking missing values for SBUX.csv:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Data Types**"
      ],
      "metadata": {
        "id": "LmrIy9QPOVoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    print(f\"\\nData types in {name}:\")\n",
        "    print(df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJhhMhm2Leoz",
        "outputId": "d550b6d2-4c9b-4cc6-ef1e-fd54f2f93253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data types in YUM.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in LKNCY.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in DPZ.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in WEN.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in QSR.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in MCD.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in DNUT.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in BRK-A.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in PZZA.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "\n",
            "Data types in SBUX.csv:\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changing formats**"
      ],
      "metadata": {
        "id": "t7yj07edQZw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # Convert to datetime\n",
        "\n",
        "    numeric_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "    for col in numeric_cols:\n",
        "      df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    df.sort_values('Date', ascending=True, inplace=True)\n",
        "\n",
        "    dfs[name] = df\n",
        "\n",
        "    print(f\"✅ Cleaned dataset: {name}\")\n",
        "\n",
        "# Verify cleaned data\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\n{name} (First 5 Rows):\")\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZJrr1sOWhzd",
        "outputId": "c5506d3b-0822-4809-9afd-dbf1a094f87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned dataset: YUM.csv\n",
            "✅ Cleaned dataset: LKNCY.csv\n",
            "✅ Cleaned dataset: DPZ.csv\n",
            "✅ Cleaned dataset: WEN.csv\n",
            "✅ Cleaned dataset: QSR.csv\n",
            "✅ Cleaned dataset: MCD.csv\n",
            "✅ Cleaned dataset: DNUT.csv\n",
            "✅ Cleaned dataset: BRK-A.csv\n",
            "✅ Cleaned dataset: PZZA.csv\n",
            "✅ Cleaned dataset: SBUX.csv\n",
            "\n",
            "YUM.csv (First 5 Rows):\n",
            "        Date      Open      High       Low     Close  Adj Close    Volume\n",
            "0 1997-09-17  5.167146  5.436736  5.167146  5.234543   3.617383  29185406\n",
            "1 1997-09-18  5.301941  5.414270  5.257009  5.414270   3.741585   6731884\n",
            "2 1997-09-19  5.403037  5.571531  5.403037  5.436736   3.757111   3440221\n",
            "3 1997-09-22  5.391804  5.459202  5.380572  5.391804   3.726059   5831072\n",
            "4 1997-09-23  5.391804  5.414270  5.380572  5.391804   3.726059   2738601\n",
            "\n",
            "LKNCY.csv (First 5 Rows):\n",
            "        Date   Open       High        Low      Close  Adj Close    Volume\n",
            "0 2019-05-17  25.02  25.959999  18.809999  20.379999  20.379999  38937500\n",
            "1 2019-05-20  21.02  21.020000  18.400000  18.610001  18.610001   8186600\n",
            "2 2019-05-21  18.59  18.740000  17.330000  17.330000  17.330000   8572300\n",
            "3 2019-05-22  17.00  17.330000  14.700000  14.750000  14.750000  19697300\n",
            "4 2019-05-23  14.47  15.950000  13.710000  15.790000  15.790000   9626500\n",
            "\n",
            "DPZ.csv (First 5 Rows):\n",
            "        Date   Open   High    Low  Close  Adj Close    Volume\n",
            "0 2004-07-13  14.00  14.10  13.49  13.50   6.144002  14964100\n",
            "1 2004-07-14  13.50  13.55  12.91  13.44   6.116695   2801000\n",
            "2 2004-07-15  13.45  13.85  13.35  13.84   6.298741   1276200\n",
            "3 2004-07-16  13.87  13.90  13.51  13.83   6.294190   1488200\n",
            "4 2004-07-19  13.80  13.80  13.35  13.52   6.153106    966200\n",
            "\n",
            "WEN.csv (First 5 Rows):\n",
            "        Date  Open   High    Low  Close  Adj Close  Volume\n",
            "0 1980-05-06   0.0  2.250  2.125  2.125   0.401966     300\n",
            "1 1980-05-07   0.0  2.375  2.250  2.250   0.425611    2000\n",
            "2 1980-05-08   0.0  2.375  2.250  2.375   0.449256    1700\n",
            "3 1980-05-09   0.0  2.375  2.250  2.375   0.449256     700\n",
            "4 1980-05-12   0.0  2.375  2.250  2.250   0.425611    1800\n",
            "\n",
            "QSR.csv (First 5 Rows):\n",
            "        Date       Open       High        Low      Close  Adj Close   Volume\n",
            "0 2014-12-11  35.049999  36.970001  34.880001  36.709999  28.332481   601900\n",
            "1 2014-12-12  37.220001  37.520000  35.049999  35.410000  27.329147  3836400\n",
            "2 2014-12-15  35.869999  35.950001  34.860001  35.290001  27.236544  1898600\n",
            "3 2014-12-16  35.410000  35.750000  35.349998  35.459999  27.367741  4877500\n",
            "4 2014-12-17  35.470001  36.599998  35.439999  36.169998  27.915712  2500200\n",
            "\n",
            "MCD.csv (First 5 Rows):\n",
            "        Date  Open      High       Low     Close  Adj Close   Volume\n",
            "0 1966-07-05   0.0  0.273663  0.267490  0.269547   0.115991   388800\n",
            "1 1966-07-06   0.0  0.283951  0.267490  0.283951   0.122190   692550\n",
            "2 1966-07-07   0.0  0.291152  0.271605  0.273663   0.117762  1858950\n",
            "3 1966-07-08   0.0  0.276749  0.267490  0.276749   0.119090  1239300\n",
            "4 1966-07-11   0.0  0.283951  0.272634  0.275720   0.118648   656100\n",
            "\n",
            "DNUT.csv (First 5 Rows):\n",
            "        Date       Open       High    Low      Close  Adj Close    Volume\n",
            "0 2021-07-01  16.299999  21.690001  15.50  21.000000  20.361467  40888200\n",
            "1 2021-07-02  19.854000  20.450001  18.32  19.120001  18.538637   8631400\n",
            "2 2021-07-06  18.900000  19.120001  17.00  17.000000  16.483095   3973000\n",
            "3 2021-07-07  17.289000  18.160000  17.00  17.780001  17.239378   3213500\n",
            "4 2021-07-08  17.250000  18.350000  17.00  18.200001  17.646606   5448300\n",
            "\n",
            "BRK-A.csv (First 5 Rows):\n",
            "        Date   Open   High    Low  Close  Adj Close  Volume\n",
            "0 1980-03-17  290.0  310.0  290.0  290.0      290.0   10000\n",
            "1 1980-03-18  290.0  290.0  290.0  290.0      290.0       0\n",
            "2 1980-03-19  290.0  310.0  290.0  290.0      290.0   20000\n",
            "3 1980-03-20  290.0  290.0  290.0  290.0      290.0       0\n",
            "4 1980-03-21  290.0  290.0  290.0  290.0      290.0       0\n",
            "\n",
            "PZZA.csv (First 5 Rows):\n",
            "        Date      Open      High       Low     Close  Adj Close    Volume\n",
            "0 1993-06-08  2.000000  2.055556  1.888889  1.944444   1.635053  16986600\n",
            "1 1993-06-09  2.000000  2.222222  1.944444  2.194444   1.845275   2650500\n",
            "2 1993-06-10  2.250000  2.333333  2.055556  2.111111   1.775201   3562200\n",
            "3 1993-06-11  2.083333  2.277778  2.083333  2.250000   1.891991   1931400\n",
            "4 1993-06-14  2.305556  2.333333  2.222222  2.333333   1.962063    730800\n",
            "\n",
            "SBUX.csv (First 5 Rows):\n",
            "        Date      Open      High       Low     Close  Adj Close     Volume\n",
            "0 1992-06-26  0.328125  0.347656  0.320313  0.335938   0.259137  224358400\n",
            "1 1992-06-29  0.339844  0.367188  0.332031  0.359375   0.277216   58732800\n",
            "2 1992-06-30  0.367188  0.371094  0.343750  0.347656   0.268176   34777600\n",
            "3 1992-07-01  0.351563  0.359375  0.339844  0.355469   0.274203   18316800\n",
            "4 1992-07-02  0.359375  0.359375  0.347656  0.355469   0.274203   13996800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding zero values(if any) in all the columns and rows**"
      ],
      "metadata": {
        "id": "KKWbmuDtQFLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Find columns where all values are 0\n",
        "    zero_columns = [col for col in df.columns if (df[col] == 0).all()]\n",
        "\n",
        "    # Count total rows and columns containing 0 values\n",
        "    zero_value_rows = (df == 0).any(axis=1).sum()  # Count rows containing at least one 0\n",
        "    zero_value_columns = (df == 0).any().sum()  # Count columns containing at least one 0\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nDataset: {file}\")\n",
        "    print(f\"Columns with only 0 values: {zero_columns}\" if zero_columns else \"No columns have only 0 values.\")\n",
        "    print(f\"Rows containing at least one 0: {zero_value_rows}\")\n",
        "    print(f\"Columns containing at least one 0: {zero_value_columns}\")\n",
        "\n",
        "    zero_columns_in_all_datasets = {}\n",
        "\n",
        "    zero_columns = [col for col in df.columns if (df[col] == 0).any()]\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nDataset: {file}\")\n",
        "    if zero_columns:\n",
        "        print(f\"Columns with zero values: {zero_columns}\")\n",
        "    else:\n",
        "        print(\"No columns contain zero values.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOVCzJkbMUIC",
        "outputId": "db86faf6-8bcf-41a2-f482-75b3fe7f02f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: YUM.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 0\n",
            "Columns containing at least one 0: 0\n",
            "\n",
            "Dataset: YUM.csv\n",
            "No columns contain zero values.\n",
            "\n",
            "Dataset: LKNCY.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 27\n",
            "Columns containing at least one 0: 1\n",
            "\n",
            "Dataset: LKNCY.csv\n",
            "Columns with zero values: ['Volume']\n",
            "\n",
            "Dataset: DPZ.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 0\n",
            "Columns containing at least one 0: 0\n",
            "\n",
            "Dataset: DPZ.csv\n",
            "No columns contain zero values.\n",
            "\n",
            "Dataset: WEN.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 2913\n",
            "Columns containing at least one 0: 2\n",
            "\n",
            "Dataset: WEN.csv\n",
            "Columns with zero values: ['Open', 'Volume']\n",
            "\n",
            "Dataset: QSR.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 0\n",
            "Columns containing at least one 0: 0\n",
            "\n",
            "Dataset: QSR.csv\n",
            "No columns contain zero values.\n",
            "\n",
            "Dataset: MCD.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 852\n",
            "Columns containing at least one 0: 1\n",
            "\n",
            "Dataset: MCD.csv\n",
            "Columns with zero values: ['Open']\n",
            "\n",
            "Dataset: DNUT.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 0\n",
            "Columns containing at least one 0: 0\n",
            "\n",
            "Dataset: DNUT.csv\n",
            "No columns contain zero values.\n",
            "\n",
            "Dataset: BRK-A.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 427\n",
            "Columns containing at least one 0: 1\n",
            "\n",
            "Dataset: BRK-A.csv\n",
            "Columns with zero values: ['Volume']\n",
            "\n",
            "Dataset: PZZA.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 0\n",
            "Columns containing at least one 0: 0\n",
            "\n",
            "Dataset: PZZA.csv\n",
            "No columns contain zero values.\n",
            "\n",
            "Dataset: SBUX.csv\n",
            "No columns have only 0 values.\n",
            "Rows containing at least one 0: 0\n",
            "Columns containing at least one 0: 0\n",
            "\n",
            "Dataset: SBUX.csv\n",
            "No columns contain zero values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Anomalies**"
      ],
      "metadata": {
        "id": "1VRT5l4YQrgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    Q1 = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']].quantile(0.25)\n",
        "    Q3 = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define boundaries for anomalies\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identify anomalies\n",
        "    anomalies = ((df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']] < lower_bound) |\n",
        "                 (df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']] > upper_bound))\n",
        "\n",
        "    print(f\"Dataset: {name} - Anomalies Found:\\n\", anomalies.sum())  # Check how many anomalies exist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6PFeuT8YDAu",
        "outputId": "092e3be9-936b-42a3-f4c2-089d73133ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: YUM.csv - Anomalies Found:\n",
            " Open           0\n",
            "High           0\n",
            "Low            0\n",
            "Close          0\n",
            "Adj Close      0\n",
            "Volume       270\n",
            "dtype: int64\n",
            "Dataset: LKNCY.csv - Anomalies Found:\n",
            " Open           6\n",
            "High           7\n",
            "Low            5\n",
            "Close          5\n",
            "Adj Close      5\n",
            "Volume       171\n",
            "dtype: int64\n",
            "Dataset: DPZ.csv - Anomalies Found:\n",
            " Open           0\n",
            "High           0\n",
            "Low            0\n",
            "Close          0\n",
            "Adj Close      0\n",
            "Volume       297\n",
            "dtype: int64\n",
            "Dataset: WEN.csv - Anomalies Found:\n",
            " Open           0\n",
            "High           0\n",
            "Low            0\n",
            "Close          0\n",
            "Adj Close    749\n",
            "Volume       632\n",
            "dtype: int64\n",
            "Dataset: QSR.csv - Anomalies Found:\n",
            " Open           1\n",
            "High           0\n",
            "Low            2\n",
            "Close          1\n",
            "Adj Close      1\n",
            "Volume       166\n",
            "dtype: int64\n",
            "Dataset: MCD.csv - Anomalies Found:\n",
            " Open         1677\n",
            "High         1671\n",
            "Low          1658\n",
            "Close        1666\n",
            "Adj Close    1905\n",
            "Volume        703\n",
            "dtype: int64\n",
            "Dataset: DNUT.csv - Anomalies Found:\n",
            " Open         11\n",
            "High         16\n",
            "Low           8\n",
            "Close        12\n",
            "Adj Close    11\n",
            "Volume       58\n",
            "dtype: int64\n",
            "Dataset: BRK-A.csv - Anomalies Found:\n",
            " Open         833\n",
            "High         834\n",
            "Low          822\n",
            "Close        828\n",
            "Adj Close    828\n",
            "Volume       545\n",
            "dtype: int64\n",
            "Dataset: PZZA.csv - Anomalies Found:\n",
            " Open          79\n",
            "High          76\n",
            "Low           81\n",
            "Close         79\n",
            "Adj Close    120\n",
            "Volume       548\n",
            "dtype: int64\n",
            "Dataset: SBUX.csv - Anomalies Found:\n",
            " Open           0\n",
            "High           0\n",
            "Low            0\n",
            "Close          0\n",
            "Adj Close      6\n",
            "Volume       460\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filling \"open\" column with previous values of \"close\" values**"
      ],
      "metadata": {
        "id": "uGur7jv8CXcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df.loc[df['Open'] == 0, 'Open'] = df['Close'].shift(1)\n"
      ],
      "metadata": {
        "id": "6RQZdM-YQyqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Re-checking for zero values**"
      ],
      "metadata": {
        "id": "1GmdnOX7bNBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    print(f\"{name} - Zero Values After Fix:\")\n",
        "    print((df == 0).sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUyY49KwK9AB",
        "outputId": "5bff76cd-a6c1-4cb7-dc5b-cd69c73f8d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YUM.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "LKNCY.csv - Zero Values After Fix:\n",
            "Date          0\n",
            "Open          0\n",
            "High          0\n",
            "Low           0\n",
            "Close         0\n",
            "Adj Close     0\n",
            "Volume       27\n",
            "dtype: int64\n",
            "DPZ.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "WEN.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       3\n",
            "dtype: int64\n",
            "QSR.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "MCD.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "DNUT.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "BRK-A.csv - Zero Values After Fix:\n",
            "Date           0\n",
            "Open           0\n",
            "High           0\n",
            "Low            0\n",
            "Close          0\n",
            "Adj Close      0\n",
            "Volume       427\n",
            "dtype: int64\n",
            "PZZA.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "SBUX.csv - Zero Values After Fix:\n",
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Outliers by capping extreme values**"
      ],
      "metadata": {
        "id": "uVKe85kxbTM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Volume'] = df['Volume'].astype(float).clip(lower=df['Volume'].quantile(0.05),\n",
        "                                                   upper=df['Volume'].quantile(0.95)).astype(df['Volume'].dtype)"
      ],
      "metadata": {
        "id": "nhX9oJQHbSvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "mijYzWY0krLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Daily Returns**"
      ],
      "metadata": {
        "id": "-MDsAbSids31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Daily_Return'] = df['Adj Close'].pct_change()  # Percentage change\n"
      ],
      "metadata": {
        "id": "adR9jUz8dsi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Calculating Moving Averages**"
      ],
      "metadata": {
        "id": "_mIFElt4hQt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['MA_7'] = df['Adj Close'].rolling(window=7).mean()  # 7-day moving average\n",
        "    df['MA_30'] = df['Adj Close'].rolling(window=30).mean()  # 30-day moving average\n"
      ],
      "metadata": {
        "id": "yi6oZy4chRJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing Volatility (Rolling Standard Deviation)**"
      ],
      "metadata": {
        "id": "MmSsE088hUhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Volatility_7'] = df['Daily_Return'].rolling(window=7).std()\n",
        "    df['Volatility_30'] = df['Daily_Return'].rolling(window=30).std()\n"
      ],
      "metadata": {
        "id": "uaCKVM7uhUty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Price Range Feature**"
      ],
      "metadata": {
        "id": "GAtS8ClOhXOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Price_Range'] = df['High'] - df['Low']\n"
      ],
      "metadata": {
        "id": "__FO62mFhXUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lag Features (Past Values as Features)**"
      ],
      "metadata": {
        "id": "1a5frL5MhmQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lag features (Previous day's Close price)\n",
        "for name, df in dfs.items():\n",
        "    df['Close_Lag_1'] = df['Close'].shift(1)\n",
        "    df['Close_Lag_5'] = df['Close'].shift(5)  # Close price 5 days ago\n",
        "    df['Volume_Lag_1'] = df['Volume'].shift(1)\n"
      ],
      "metadata": {
        "id": "JF_2qISfhmau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log Returns**"
      ],
      "metadata": {
        "id": "EyqEQqPzi67c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "for name, df in dfs.items():\n",
        "    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))"
      ],
      "metadata": {
        "id": "iYX72y5Mi7BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cumulative Returns**"
      ],
      "metadata": {
        "id": "9ZOdMwtii97f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Cumulative_Return'] = (1 + df['Daily_Return']).cumprod()\n"
      ],
      "metadata": {
        "id": "Mwjx5mrwi-Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relative Strength Index (RSI)**"
      ],
      "metadata": {
        "id": "v-PMzMmAjBgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_RSI(data, window=14):\n",
        "    delta = data['Close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "\n",
        "    RS = gain / loss\n",
        "    RSI = 100 - (100 / (1 + RS))\n",
        "    return RSI\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    df['RSI'] = compute_RSI(df)\n"
      ],
      "metadata": {
        "id": "JSSLvvwzjBmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bollinger Bands**"
      ],
      "metadata": {
        "id": "lSW8sVpSjERT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['BB_Upper'] = df['MA_20'] + (df['Close'].rolling(window=20).std() * 2)\n",
        "    df['BB_Lower'] = df['MA_20'] - (df['Close'].rolling(window=20).std() * 2)\n"
      ],
      "metadata": {
        "id": "rsI3CDXMjEXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Volume-Based Features**"
      ],
      "metadata": {
        "id": "sx63_e51jJer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    df['Volume_Change'] = df['Volume'].pct_change()\n",
        "    df['Volume_MA_10'] = df['Volume'].rolling(window=10).mean()\n"
      ],
      "metadata": {
        "id": "5xF4VGBwjJkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date-Based Feature Engineering**"
      ],
      "metadata": {
        "id": "kEmsD9Nzk6ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' column to datetime format\n",
        "for name, df in dfs.items():\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Extract date-related features\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Weekday'] = df['Date'].dt.weekday  # Monday=0, Sunday=6\n",
        "    df['Day_of_Week'] = df['Date'].dt.day_name()\n",
        "    df['Quarter'] = df['Date'].dt.quarter"
      ],
      "metadata": {
        "id": "k_yDxhCmk61H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking all the columns**"
      ],
      "metadata": {
        "id": "vVvGeaqPqphc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiKx-j_gXp3k",
        "outputId": "7787c5b0-36ad-4575-f030-fde2214f53e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
            "       'Daily_Return', 'MA_7', 'MA_30', 'Volatility_7', 'Volatility_30',\n",
            "       'Price_Range', 'Close_Lag_1', 'Close_Lag_5', 'Volume_Lag_1',\n",
            "       'Log_Return', 'Cumulative_Return', 'RSI', 'MA_20', 'BB_Upper',\n",
            "       'BB_Lower', 'Volume_Change', 'Volume_MA_10', 'Year', 'Month', 'Weekday',\n",
            "       'Day_of_Week', 'Quarter'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Missing Values Only in New Features**"
      ],
      "metadata": {
        "id": "_juAMklcdKIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    new_features = ['Daily_Return', 'MA_7', 'MA_30', 'Volatility_7', 'Volatility_30',\n",
        "       'Price_Range', 'Close_Lag_1', 'Close_Lag_5', 'Volume_Lag_1',\n",
        "       'Log_Return', 'Cumulative_Return', 'RSI', 'MA_20', 'BB_Upper',\n",
        "       'BB_Lower', 'Volume_Change', 'Volume_MA_10', 'Year', 'Month', 'Weekday',\n",
        "       'Day_of_Week', 'Quarter']\n",
        "    missing_counts = df[new_features].isna().sum()\n",
        "    print(f\"\\nDataset: {name}\")\n",
        "    print(missing_counts[missing_counts > 0])  # Show only missing values in new features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4DP5xOfZicl",
        "outputId": "4f89e92f-13b3-47a7-b42a-8ee58201d7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: YUM.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: LKNCY.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  30\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: DPZ.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: WEN.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  23\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: QSR.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: MCD.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: DNUT.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: BRK-A.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  35\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: PZZA.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n",
            "\n",
            "Dataset: SBUX.csv\n",
            "Daily_Return          1\n",
            "MA_7                  6\n",
            "MA_30                29\n",
            "Volatility_7          7\n",
            "Volatility_30        30\n",
            "Close_Lag_1           1\n",
            "Close_Lag_5           5\n",
            "Volume_Lag_1          1\n",
            "Log_Return            1\n",
            "Cumulative_Return     1\n",
            "RSI                  13\n",
            "MA_20                19\n",
            "BB_Upper             19\n",
            "BB_Lower             19\n",
            "Volume_Change         1\n",
            "Volume_MA_10          9\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fixing Zero Values with Code**"
      ],
      "metadata": {
        "id": "SmkIfzeBdUAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    # Fill rolling calculations using backward fill (bfill)\n",
        "    rolling_cols = ['MA_7', 'MA_30', 'Volatility_7', 'Volatility_30',\n",
        "                    'MA_20', 'BB_Upper', 'BB_Lower', 'RSI', 'Volume_MA_10']\n",
        "    df[rolling_cols] = df[rolling_cols].replace(0, np.nan).bfill()\n",
        "\n",
        "    # Fill lag features using forward fill (ffill)\n",
        "    lag_cols = ['Close_Lag_1', 'Close_Lag_5', 'Volume_Lag_1']\n",
        "    df[lag_cols] = df[lag_cols].replace(0, np.nan).ffill()\n",
        "\n",
        "    print(f\"Fixed zero values for {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMvpDmlWb94M",
        "outputId": "faa2d822-6507-4421-efe0-cfdd6c7b56fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed zero values for YUM.csv\n",
            "Fixed zero values for LKNCY.csv\n",
            "Fixed zero values for DPZ.csv\n",
            "Fixed zero values for WEN.csv\n",
            "Fixed zero values for QSR.csv\n",
            "Fixed zero values for MCD.csv\n",
            "Fixed zero values for DNUT.csv\n",
            "Fixed zero values for BRK-A.csv\n",
            "Fixed zero values for PZZA.csv\n",
            "Fixed zero values for SBUX.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Re-checking for zero values ***"
      ],
      "metadata": {
        "id": "iXCaMwgmeb9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    zero_counts = (df == 0).sum()\n",
        "    print(f\"\\nDataset: {name}\")\n",
        "    print(zero_counts[zero_counts > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PuDt4ndZ6L",
        "outputId": "e3fcb3a0-9212-40a3-a7e3-c5aaf29396a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: YUM.csv\n",
            "Daily_Return       57\n",
            "Log_Return         58\n",
            "Volume_Change     276\n",
            "Weekday          1274\n",
            "dtype: int64\n",
            "\n",
            "Dataset: LKNCY.csv\n",
            "Daily_Return      47\n",
            "Price_Range       30\n",
            "Log_Return        47\n",
            "Volume_Change     79\n",
            "Weekday          249\n",
            "dtype: int64\n",
            "\n",
            "Dataset: DPZ.csv\n",
            "Daily_Return      54\n",
            "Log_Return        54\n",
            "Volume_Change    179\n",
            "Weekday          949\n",
            "dtype: int64\n",
            "\n",
            "Dataset: WEN.csv\n",
            "Daily_Return     1788\n",
            "Price_Range       174\n",
            "Log_Return       1790\n",
            "Volume_Change     542\n",
            "Weekday          2112\n",
            "dtype: int64\n",
            "\n",
            "Dataset: QSR.csv\n",
            "Daily_Return      10\n",
            "Log_Return        10\n",
            "Volume_Change    113\n",
            "Weekday          457\n",
            "dtype: int64\n",
            "\n",
            "Dataset: MCD.csv\n",
            "Daily_Return      629\n",
            "Price_Range         2\n",
            "Log_Return        634\n",
            "Volume_Change     719\n",
            "Weekday          2782\n",
            "dtype: int64\n",
            "\n",
            "Dataset: DNUT.csv\n",
            "Daily_Return      13\n",
            "Log_Return        13\n",
            "Volume_Change     32\n",
            "Weekday          147\n",
            "dtype: int64\n",
            "\n",
            "Dataset: BRK-A.csv\n",
            "Daily_Return     1465\n",
            "Price_Range      1092\n",
            "Log_Return       1465\n",
            "Volume_Change    1520\n",
            "Weekday          2120\n",
            "dtype: int64\n",
            "\n",
            "Dataset: PZZA.csv\n",
            "Daily_Return      208\n",
            "Price_Range         8\n",
            "Log_Return        208\n",
            "Volume_Change     298\n",
            "Weekday          1478\n",
            "dtype: int64\n",
            "\n",
            "Dataset: SBUX.csv\n",
            "Daily_Return      160\n",
            "Log_Return        160\n",
            "Volume_Change     311\n",
            "Weekday          1525\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fixing Zero Values in Price_Range and Checking Encoding**"
      ],
      "metadata": {
        "id": "llwD5Thqeok7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    # Replace zero values in Price_Range with NaN (if Price_Range exists in the dataset)\n",
        "    if 'Price_Range' in df.columns:\n",
        "        df['Price_Range'] = df['Price_Range'].replace(0, np.nan)\n",
        "\n",
        "    # Verify encoding of Weekday column\n",
        "    if 'Weekday' in df.columns:\n",
        "        print(f\"Unique values in Weekday for {name}: {df['Weekday'].unique()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPOmW4XOeGSO",
        "outputId": "cd120c51-6b65-4025-f8e9-7c6c573d9551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in Weekday for YUM.csv: [2 3 4 0 1]\n",
            "Unique values in Weekday for LKNCY.csv: [4 0 1 2 3]\n",
            "Unique values in Weekday for DPZ.csv: [1 2 3 4 0]\n",
            "Unique values in Weekday for WEN.csv: [1 2 3 4 0]\n",
            "Unique values in Weekday for QSR.csv: [3 4 0 1 2]\n",
            "Unique values in Weekday for MCD.csv: [1 2 3 4 0]\n",
            "Unique values in Weekday for DNUT.csv: [3 4 1 2 0]\n",
            "Unique values in Weekday for BRK-A.csv: [0 1 2 3 4]\n",
            "Unique values in Weekday for PZZA.csv: [1 2 3 4 0]\n",
            "Unique values in Weekday for SBUX.csv: [4 0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Renaming column names for SQL**"
      ],
      "metadata": {
        "id": "85FkOEeUZiUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_cleaned = {}  # Dictionary to store modified DataFrames\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    df.columns = df.columns.str.replace(' ', '_').str.lower()  # Replace spaces with underscores\n",
        "    dfs_cleaned[name] = df\n"
      ],
      "metadata": {
        "id": "rk50nOPkestN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SQL Integration**"
      ],
      "metadata": {
        "id": "R5Gs9L9xm8cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mysql-connector-python pandas sqlalchemy pymysql\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA3R5uQJm8ii",
        "outputId": "c420c1b2-376e-4955-f5ac-0ad999bbac14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.37)\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading mysql_connector_python-9.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (34.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql, mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.2.0 pymysql-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each DataFrame in the dictionary\n",
        "for name, df in dfs_cleaned.items():\n",
        "    # Save each DataFrame to a CSV file\n",
        "    df.to_csv(f'/content/{name}_cleaned_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "PGlIX9BlGeK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "# MySQL credentials\n",
        "user = 'root'  # Replace with your MySQL username\n",
        "password = 'new_password'  # Replace with your MySQL password\n",
        "host = 'localhost'  # For local MySQL server\n",
        "database = 'fast_food_stocks'  # Replace with your database name\n",
        "\n",
        "# Create the connection string\n",
        "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{database}\")\n",
        "\n",
        "# Test the connection\n",
        "try:\n",
        "    connection = engine.connect()\n",
        "    print(\"Connection to MySQL database successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "xfckRbHKUx_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all dataframes and store them in MySQL\n",
        "for name, df in dfs.items():\n",
        "    table_name = name.replace('.csv', '').lower()  # Removing .csv to use a clean table name\n",
        "    df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
        "    print(f\"Data from {name} inserted into MySQL table '{table_name}' successfully!\")"
      ],
      "metadata": {
        "id": "pDwW-gsBUzJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}